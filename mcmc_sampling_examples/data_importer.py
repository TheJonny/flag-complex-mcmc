import numpy as np

#
# rewiring-trained networks
#
def guillaume_lsnn():
    import pickle
    with open('data/dr_1.pickle', 'rb') as f:
        w_1 = pickle.load(f)['w_rec_val'] != 0
    with open('data/dr_2.pickle', 'rb') as f:
        w_2 = pickle.load(f)['w_rec_val'] != 0
    return (w_1, w_2)


def horst_128():
    import pickle
    with open('data/q-rewiring/weights_initial.pkl', 'rb') as f:
        c_ir = pickle.load(f)[1][:,:,0] != 0
    with open('data/q-rewiring/weights_final.pkl', 'rb') as f:
        c_tr = pickle.load(f)[1][:,:,0] != 0
    with open('data/q-rewiring/weights_13.pkl', 'rb') as f:
        c_13r = pickle.load(f)[1][:,:,0] != 0
    return (c_ir, c_tr, c_13r)


def michael(i=0, N=1000, p=0.02, rule='hebbian', grid='no_grid', date='2021-03-30'):
    '''currently N in {1000,5000}, p in {0.02, 0.05}, rule in {'hebbian','stdp'}, i in {0..99} '''
    import pickle
    basepath=f'data/michael/simplices-{date}/{rule}/'
    if date == '2021-03-30' and rule == 'hebbian':
        basepath += f'N{N}'
        if grid == '3d_grid':
            basepath += '_3d'
        if p == 0.02:
            exp_spec_str = "wmax20.0_T1000.0_tauplus20ms_tauminus20ms_eta1pA_Aminus0.35_rewire-from0.05-to0.02"
        elif p == 0.05:
            exp_spec_str = "wmax10.0_T1000.0_tauplus20ms_tauminus20ms_eta0.5pA_Aminus0.35_rewire-from0.12-to0.05"
        with open(f'{basepath}_{exp_spec_str}/run{i:04}/data_weights.pkl', 'rb') as f:
            return pickle.load(f).final_exact_p.W != 0

    if date == '2021-03-30' and rule == 'stdp':
        basepath += f'N{N}'
        if grid == '3d_grid':
            basepath += '_3d'
        if p == 0.02:
            exp_spec_str = "wmax40.0_T1000.0_tauplus20ms_tauminus20ms_eta1pA_alpha1.05_rewire-from0.05-to0.02"
        elif p == 0.05:
            exp_spec_str = "wmax20.0_T1000.0_tauplus20ms_tauminus20ms_eta1pA_alpha1.05_rewire-from0.12-to0.05" 
        with open(f'{basepath}_{exp_spec_str}/run{i:04}/data_weights.pkl', 'rb') as f:
            return pickle.load(f).final_exact_p.W != 0


def zenke2015(con_group='all', fraction=1):
    import pickle
    with open(f'data/zenke2015/zenke2015_w{con_group}.pkl', 'rb') as f:
        w = pickle.load(f)
    return w >= w.max()*(1-fraction)


#
# biological data - statistical reconstructions
#
def bbp(i, allowed_neuron_types='all'):
    import h5py
    h = h5py.File(f'data/bbp/average/cons_locs_pathways_mc{i}_Column.h5')
    neuron_types = list(h['connectivity'].keys())
    if type(allowed_neuron_types) is list:
        neuron_types = allowed_neuron_types
    if allowed_neuron_types in ['exc', 'inh']:
        exc_neuron_types =  [x for x  in neuron_types if 'PC' in x] + ['L4_SS', 'L4_SP']
        if allowed_neuron_types == 'exc':
            neuron_types = exc_neuron_types
        else:
            neuron_types = set(neuron_types) - set(exc_neuron_types)
    N_per_nt = [h[f'populations/{nt}/locations'].shape[0] for nt in neuron_types]
    N = sum(N_per_nt)

    c = np.zeros((N,N), dtype='bool')
    inds = np.cumsum([0]+N_per_nt)
    for i, nti in enumerate(neuron_types):
        for j, ntj in enumerate(neuron_types):
            c[inds[i]:inds[i+1], inds[j]:inds[j+1]] = h[f'connectivity/{nti}/{ntj}/cMat'][:]
    return c


def mouse_v1(run=0, fraction=1.00, allowed_neuron_types=None, compress_sparse_matrix=False):
    '''
    Import mouse_v1 from Billeh et al. mouse primary visual cortex sparse reconstruction:
    https://pubmed.ncbi.nlm.nih.gov/32142648/

    The connectome files are generated by the network_builder script available at 
    https://www.dropbox.com/sh/w5u31m3hq6u2x5m/AACpYpeWnm6s_qJDpmgrYgP7a?dl=0
    and are generated with a command like
    python3 build_network.py -o network_${FRACTION}_$SATID/ --fraction $FRACTION v1

    The allowed_neuron_types parameter might be either None or 'all' (for the full connectome), or 'e' or 'i' for
    excitatory or inhibitory.
    Furthermore, just passing a list of node types (inspect v1_node_types to see how they look like) should work as
    well (not tested).
    '''
    
    import pandas as pd
    import h5py
    from scipy.sparse import coo_matrix
    v1_node_types = pd.read_csv(f'data/mouse_v1/network_{fraction:.2f}_{run:02}/v1_node_types.csv', sep=' ')
    #import pudb; pu.db #inspect node types
    if allowed_neuron_types in [None, 'all']:
        allowed_neuron_types = list(v1_node_types['node_type_id'])
    if allowed_neuron_types in ['e', 'i']:
        allowed_neuron_types = list(v1_node_types[v1_node_types['ei'] == allowed_neuron_types]['node_type_id'])

    edges_h5 = h5py.File(f'data/mouse_v1/network_{fraction:.2f}_{run:02}/v1_v1_edges.h5', 'r')
    edges = edges_h5['edges/v1_to_v1/']
    nodes_h5 = h5py.File(f'data/mouse_v1/network_{fraction:.2f}_{run:02}/v1_nodes.h5', 'r')
    node_type_id = nodes_h5['nodes/v1/node_type_id']
    N = len(node_type_id)
    sources = np.asarray(edges['source_node_id'])
    sources_filtered = np.isin([node_type_id[i] for i in list(sources)], allowed_neuron_types)
    targets = np.asarray(edges['target_node_id'])
    targets_filtered = np.isin([node_type_id[i] for i in list(targets)], allowed_neuron_types)
    entries = targets_filtered & sources_filtered

    if compress_sparse_matrix: #TODO: reduce size of resulting matrix bei removing vertices w/o edges
        raise NotImplementedError
    else:
        return coo_matrix((entries, (targets, sources)), (N,N))
    
#
# biological data - dense reconstructions
#
def c_elegans():
    # 279 neurons with 2194 directed synapses taken from https://github.com/lrvarshney/elegans which represent
    # the chemical network in C.elegans according to
    # https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1001066
    from scipy.io import loadmat
    A = loadmat('data/c.elegans/A_sendjoint.mat')['Ac']
    return (A != 0).toarray()

def mpg_2013():
    # 2013: Connectomic reconstruction of the inner plexiform layer in the mouse retina
    # Moritz Helmstaedter, Kevin Briggman, Srinivas Turaga, Viren Jain, Sebastian Seung & Winfried Denk,
    # Nature, 8 August 2013, doi: 10.1038/nature12346
    import pandas as pd
    contact_matrix = pd.read_excel('data/mpg_2013/Helmstaedter_et_al_SUPPLinformation4.xlsx')
    x = contact_matrix.to_numpy()[:,1:]
    import pudb; pu.db
    raise NotImplementedError

def mpg_2019():
    # 2019: Dense Connectomic Reconstruction in Layer 4 of the Somatosensory Cortex
    # Alessandro Motta1*, Manuel Berning1*, Kevin M. Boergens1*, Benedikt Staffler1*, Marcel Beining1, Sahil Loomba1, Philipp Hennig2, Heiko Wissler1, Moritz Helmstaedter1â€ .
    # Science (2019). DOI: 10.1126/science.aay3134
    import pudb; pu.db
    import pandas as pd
    con = pd.read_csv('data/mpg_2019/connectome.csv')

def drosophila_2020(min_weight=1, roi=None, update=False):
    '''
    Load the 2020 drosophila dense reconstruction connectome or parts of it. See Scheffer et al.: https://elifesciences.org/articles/57443
    '''
    import pickle    
    from scipy.sparse import coo_matrix
    if update:
        import neuprint
        c = neuprint.Client('neuprint.janelia.org',
                dataset='hemibrain:v1.2',
                token='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6ImZsb3JpYW4udW5nZXJAcG9zdGVvLm5ldCIsImxldmVsIjoibm9hdXRoIiwiaW1hZ2UtdXJsIjoiaHR0cHM6Ly9saDMuZ29vZ2xldXNlcmNvbnRlbnQuY29tLy1hWkRMZFhOdHRnay9BQUFBQUFBQUFBSS9BQUFBQUFBQUFBQS9BTVp1dWNubk5sZ3pPRHBfSjBmblNYSDJjaFppb1lIcUpBL3M5Ni1jL3Bob3RvLmpwZz9zej01MD9zej01MCIsImV4cCI6MTc5NzEyNjMzNn0.rtm-sQhyymfPmdr5GcQPMinq3PE8G2ecri-EZKDMego'  #token associated to Florian Unger, please don't abuse.
                )
        fa = neuprint.fetch_adjacencies()
        with open('data/drosophila_2020/fetch_adjacencies.pkl', 'wb') as f:
            pickle.dump(fa,f)

    with open('data/drosophila_2020/fetch_adjacencies.pkl', 'rb') as f:
        nl, cl = pickle.load(f)

    possible_roi = set(cl['roi'][:]) 
    #print possible_roi  

    if roi in possible_roi:
        cl = cl[cl['roi'] == roi];

    cl = cl[cl['weight'] >= min_weight]

    #renumber synapses
    neuron_set = set(cl['bodyId_pre']) | set(cl['bodyId_post'])
    bodyId_to_id = {x:i for i,x in enumerate(neuron_set)}

    #build sparse_matrix
    N = len(neuron_set)
    presynaptic_id = [bodyId_to_id[i] for i in cl['bodyId_pre']]
    postsynaptic_id = [bodyId_to_id[i] for i in cl['bodyId_post']]
    x = coo_matrix((cl['weight'],(presynaptic_id, postsynaptic_id)), (N,N))
    return x != 0




#
# others 
#

def random_spatial(i=0, N=1000, p=0.02):
    import pickle
    with open(f'data/random_spatial/random_spatial_N{N}_p{p}_{i:02}.pkl', 'rb') as f:
        x = pickle.load(f)
    return x

#
# examples from papers
#
def S6C():
    'simplicial complex of Figure S6C in paper'
    li = [0,0,0,1,2,2,3,4,4,5]
    lj = [1,2,3,2,3,4,4,5,6,6]
    return densifier(li,lj)


def S6Cmod():
    'simplicial complex of Figure S6C with added edge from 2 to 4'
    W = S6C()
    W[3,1] = 1
    return W


def flag_e():
    'corrensponds to test/e.flag in flagser'
    li = [0,1,0,3,3,3,4,4,4]
    lj = [1,2,2,0,1,2,0,1,2]
    return densifier(li,lj,N=5)


#
# artifical examples
#
def simplex(d):
    '''returns a d+1 weight matrix corresponding to a simplex of dimension d'''
    return np.tril(np.ones((d+1,d+1)), k=-1)


def clique(d):
    '''returns a d+1 weight matrix corresponding to a clique of size d+1: A graph with d+1 nodes and all posible edges
    except reflexive ones'''
    c = np.ones((d+1,d+1))
    np.fill_diagonal(c, 0)
    return c



#
# 0 models for comparison
#
def random_like(c, exact=False):
    '''return a connectome matrix of shape like A, with a global connection density like A and empty main diagonal'''
    assert c.ndim == 2 and c.shape[0] == c.shape[1]

    D = c.shape[0]
    num_nonzero = (c != 0).sum()

    if exact:
        ones = np.zeros(D * (D - 1))
        ones[:num_nonzero] = 1
        np.random.shuffle(ones)

        c0 = np.zeros((D, D))
        c0[np.where(~np.eye(D, dtype=bool))] = ones

        assert c0.sum() == num_nonzero
        assert (np.diagonal(c0) == 0).all()

    else:
        p = num_nonzero / D**2
        c0 = np.random.binomial(1, p=p, size=c.shape)
        np.fill_diagonal(c0, 0)

    return c0


def random_with_p(N, p):
    '''returns a binary (N, N) matrix with connection probability of p on every edge except the diagonal'''
    c = np.random.uniform(size=(N, N)) < p * (N**2) / (N**2 - N)
    np.fill_diagonal(c, 0)
    return c

def random_like_c_same_dep(c):
    ''' returns a random binary matrix shaped like c, empty on the diagonal, with sameish connection probability and sameish
    double edge probability (dep)'''
    assert c.ndim == 2 and c.shape[0] == c.shape[1]
    N = c.shape[0]

    #generate overdense random matrix
    p_tar = (c!=0).sum() / (N**2-N)
    dep_tar = ((c!=0) & (c.transpose()!=0)).sum() * 2 / (N**2-N)
    
    q = 1 - (1 + dep_tar - 2*p_tar)**.5

    x = np.random.uniform(size=(N,N)) < q
    import pudb; pu.db
    # delete double edges until there are only as many double edges left as in c
    # CURRENTLY DELETES ALL DOUBLE EDGES: FIX ME!
    double_edges = np.where((x==1) & (x.transpose()==1))
    for (i,j) in zip(*double_edges):
        if np.random.uniform() < 0.5:
            x[i,j] = 0
        else:
            x[j,i] = 0
    return x




###
# helper

def densifier(li, lj):
    #assume min vertex is 0
    N = max(li+lj) + 1
    r = np.zeros((N,N))
    for i,j in zip(li,lj):
        r[i,j] = 1
    return r
